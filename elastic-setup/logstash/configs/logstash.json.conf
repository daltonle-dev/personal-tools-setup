input {
    file {
        path => "path_to_json_file/file_name.json"
        # instruct logstash read from beginning, this setting only applies to file that are read for the first time.
        # By default, program would prefer to read from the end.
        # Since it processes the file that would have data added to it periodically.
        start_position => "beginning"
        # sincedb_path points to the db file that keeps track of the last parsed in the input file.
        # Set to "/dev/null" will process entire the file each time from beginning 
        # rather than continue from where it left off.
        sincedb_path => "/dev/null"
    }
}

filter {
    json {
        source => "message"
    }

    if [paymentTyp] == "Mastercard" {
        drop {
        }
    }

    split {
        field => "[pastEvents]"
    }

    mutate {
        convert => {
            "age" => "integer"
        }
        add_field => {
            "eventId" => "%{[pastEvents][eventId]}"
            "transactionId" => "%{[pastEvents][transactionId]}"
        }
        remove_field => ["message", "@timestamp", "path", "host", "@version", "pastEvents"]
    }
}

output {
    stdout {
    }

    elasticsearch {
        index => "logstash-%{+YYYY.MM.dd}"
        hosts => "${ELASTIC_HOSTS}"
        user => "${ELASTIC_USER}"
        password => "${ELASTIC_PASSWORD}"
        cacert => "certs/ca/ca.crt"
    }
}
